\documentclass[a4j]{jsarticle}

\usepackage{listings}
\usepackage{color}
\usepackage{ascmac, here, txfonts, txfonts}
\usepackage[dvipdfmx]{graphicx}
\usepackage{comment}
\usepackage{otf}

\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}

\renewcommand{\lstlistingname}{ソースコード}


\begin{document}

\begin{titlepage}
  \title{情報特別演習\ajRoman{2}　最終レポート\\ Kinectによる自然な姿勢推定の実現}
  \author{情報科学類2年\\堤海斗}
  \maketitle
  \thispagestyle{empty}
  
\end{titlepage}

\begin{comment}
  ・演習概要
    ・演習テーマと背景
    ・演習目的
  ・演習手法
    ・FKによる姿勢推定
    ・自然な姿勢推定
      ・IKの導入
      ・キャリブレーションの導入
      ・フィルターの導入
  ・演習結果とまとめ
    ・実装結果
    ・現在取り組んでいる項目
    ・今後の展望
    ・演習で得られたこと
\end{comment}

\section{演習概要}

\subsection{演習目的}

今年の情報特別演習\ajRoman{2}では、「Kinectによる自然な姿勢推定の実現」
というテーマで1年間演習をしてきた。
本演習の目的は、Kinect v2というデバイスを用いて人の動きをセンサリングし、
そのデータを人型アバターに反映するという一連のシステム、つまり
モーションキャプチャシステムの実装において、
より自然な姿勢推定を実現することを目的としている。

本演習では以下の環境を用いる

\begin{itemize}
  \item Kinect v2
  \item Unity 2018.4.xx 
\end{itemize}

\subsection{演習の背景}

前述のとおり本演習ではKinect v2というデバイスを使うのだが、
このデバイスはMicrosoftが開発していた赤外線カメラデバイスの1種である。
このデバイスではカラーカメラによって通常のカラー画像をはじめ、
赤外線による深度画像が取得可能である。
加えて深度画像を解析して人間を検知し、人の関節データを取得することが可能である。
Kinectだけでも姿勢推定は可能なのだが、
今回はUnityを用いてVRMやMMDといった人型アバターモデルに適用することで、
モーションキャプチャをしようと考えた。

このようなテーマにした理由として、昨今のVTuberブームが挙げられる。
2017年下旬から”VTuber”とよばれるコンテンツが話題になっていた。
VTuberとは人間の動きをモーションキャプチャによってバーチャルなキャラクターに反映し、
Youtubeなどの動画配信プラットフォームで動画投稿や配信活動をするコンテンツである。

私はこのVTuberにとても興味があり、
このようなものを自分でも実現してみたいと思い、このテーマを選択した。
Kinect v2は最初に今回演習で担当をして下さっている志築先生のIPLABからお借りして、
その後に、夏の長期休み明けからは自分の私物を使った。

\subsection{モーションキャプチャについて}

本演習ではモーションキャプチャシステムを作ることが目的であるので、
そもそもモーションキャプチャとは何かについて説明する。

前節で少し言及した通り、モーションキャプチャとは
人をはじめとしたものの動き(モーション)をセンサリングで取得する(キャプチャ)ことである。
モーションキャプチャを利用して、前述したVTuberやゲームキャラクターのモーション作成、
ジェスチャーインプットを使ったアプリケーションの作成などができる。

モーションキャプチャを行うには、モーションキャプチャができるデバイスが必要だが、
どの程度のモーションキャプチャが必要かどうかによって必要な機材が変わってくる。
例えば、上半身だけのモーショントラッキングであれば、
顔の位置と表情をトラキングできればよいのでスマホ1台でもできる。
そこに手の動きを加えたければLeapMotionなどのデバイスを使う。
また、立った姿でトラッキングをするとなると、VRセットが活用できる。
Oculus Questなどのデバイスを使うことによって
VRアプリケーションを操作するために最適なモーションキャプチャが可能である。

今回の演習では、全身を使った、いわゆるフルトラッキング・モーションキャプチャをする。
フルトラッキングができるデバイスの例を以下に示す。

\begin{itemize}
  \item VICON
  \item OptiTrack
  \item Vive Tracker
  \item RealSense
  \item iPhone 11 Pro
\end{itemize}

精度の差はあれど、これらのデバイスをセンサーとして用いることで
モーションデータの取得が可能であり、
取得したデータを利用してアプリケーションを開発する。

本演習ではKinect v2を使ってモーションキャプチャをするわけだが、
前述のとおり、Kinect v2では、Kinect自身でモーションキャプチャが完結しており、
モーションデータをUnityやC++アプリケーションでリアルタイムに取得可能である。
Kinect v2の主な特徴は以下のとおりである。

\begin{itemize}
  \item 非接触型センサーである
  \item Unity用のSDKが配布されている
  \item 複数人のモーションキャプチャが同時にできる
  \item 開発が終了している
\end{itemize}


\section{演習手法}

\subsection{FKによる姿勢推定}

モーションキャプチャを行うにあたって、まず初めにFKという手法を用いて
アバターのボーンを制御した。

\subsection{自然な姿勢推定}

\subsubsection{IKの導入}

\subsubsection{キャリブレーションの導入}

\subsubsection{フィルターの導入}

\section{演習結果とまとめ}

\subsection{実装結果}

\subsection{現在取り組んでいる項目}

\subsection{今後の展望}

\subsection{本演習で学んだこと}


\end{document}